# Sharepoint_Shortcut_data_Ms_Fabric
ğŸ“˜ End-to-End Data Engineering Pipeline using Microsoft Fabric & SharePoint
This project demonstrates a complete end-to-end data engineering workflow built using Microsoft Fabric, including data ingestion, transformations, Lakehouse storage layers (Bronze/Silver), semantic modeling, Power BI reporting, and automated orchestration through pipelines.

# ğŸš€ Project Overview
This repository contains the code, notebooks, and resources used to build a scalable data pipeline that:

Ingests files from SharePoint using OneLake Shortcut
Stores raw data in Lakehouse (Bronze Layer)
Performs data cleaning and transformation using Fabric Notebooks
Saves curated data to Silver Layer
Builds a semantic model on top of Silver data
Creates a Power BI report
Automates the entire workflow using Fabric Data Pipelines
Supports incremental refresh whenever new files are added in SharePoint


# ğŸ—ï¸ Architecture Workflow
### 1. Data Ingestion (Bronze Layer)

Created a OneLake Shortcut to connect Fabric Lakehouse with a SharePoint document library.
Shortcut ensures auto-sync when new files are added.
Raw data is ingested directly into:
sharepoint_lakehouse > sharepointData_Bronze schema




### 2. Data Transformation (Silver Layer)


Developed a Fabric Notebook to clean and enrich the Bronze data.


### Cleaning logic includes:

Removing unwanted/duplicate rows
Handling null values:

Categorical columns â†’ filled using Mode

Numeric columns â†’ filled using Median


Standardizing column formats
Applying business rules



Final cleaned dataset saved to:
sharepoint_silver schema




### 3. Semantic Modeling

Created a Semantic Model on top of the Silver tables.
Implemented:

Relationships
Measures
Data formatting
Business-friendly naming conventions




## 4. Power BI Reporting

Built a Power BI report using the semantic model.
Visuals automatically reflect changes when new data flows through the pipeline.


## 5. Data Pipeline Orchestration


# Created a Fabric Data Pipeline to orchestrate:

Bronze ingestion
Transformation notebook execution
Silver updates
Semantic model refresh
Power BI dataset refresh



# Pipeline scheduled for automated execution.



## 6. Automatic Refresh When New SharePoint Files Arrive

#### When new files are added to the SharePoint folder:

Shortcut syncs automatically
Pipeline refresh triggers
Notebook cleans & processes new rows
Silver table updates
Semantic model refreshes
Power BI report shows new data instantly



This ensures a fully automated, scalable, and maintenance-free workflow.

# ğŸ“ Folder Structure
â”œâ”€â”€ notebooks/

â”‚   â””â”€â”€ data_cleaning_notebook.ipynb

â”œâ”€â”€ pipelines/

â”‚   â””â”€â”€ sharepoint_end_to_end_pipeline.json

â”œâ”€â”€ reports/

â”‚   â””â”€â”€ power_bi_report.pbix

â””â”€â”€ README.md


# ğŸ› ï¸ Technologies Used

Microsoft Fabric
OneLake Shortcut
Lakehouse (Delta Tables)
PySpark / Python Notebooks
Power BI
Semantic Models
Fabric Pipelines
SharePoint Online


# ğŸŒŸ Key Features

#### ğŸ”„ Fully automated ETL/ELT workflow
#### ğŸ—‚ï¸ Multi-layer architecture: Bronze â†’ Silver
#### âš™ï¸ Notebook-driven data transformations
#### ğŸ”— Live SharePoint integration via OneLake shortcuts
#### ğŸ“Š Dynamic Power BI reporting
#### â±ï¸ Scheduled + event-driven refresh
#### ğŸ“ˆ Supports incremental new-row ingestion
